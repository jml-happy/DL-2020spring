{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Digit Image Classification MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ehzTqE4tDOkI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Digits Image (MNIST Dataset) Classification using CNNs  \n",
        "**Classify the images of digits (0, 1, 2, etc.) correctly using Convolutional Neural Networks**  \n",
        "**Reference: https://www.kaggle.com/c/digit-recognizer/kernels**"
      ]
    },
    {
      "metadata": {
        "id": "v5J5g7zpCLdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Verify that all requires libraries can be imported"
      ]
    },
    {
      "metadata": {
        "id": "TTn-dOAKCLdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6e740fb-7fb7-4563-9a0b-25a13be58d29"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "scuh8OJnCLdN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load MNIST dataset from the Internet  \n",
        "**The path for MNIST dataset is already in the Keras datasets library**  \n",
        "**The mnist.load_data() module automatically returns the four sets of data we need** "
      ]
    },
    {
      "metadata": {
        "id": "mixrJeYxCLdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "( train_images, train_labels ), ( validation_images, validation_labels ) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fiay5uU0EhDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Check how many images are in the Training set and Validation set\n",
        "** What is the dimension of each image?**"
      ]
    },
    {
      "metadata": {
        "id": "CbiupfMXEiiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "45689f22-c565-4b7a-c434-92a495269e78"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training dataset:\")\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print('Validation dataset:')\n",
        "print(validation_images.shape)\n",
        "print(validation_labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset:\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "Validation dataset:\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5Q0TUrGCLdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Visualize a random image (for example, 0th image) in the train dataset"
      ]
    },
    {
      "metadata": {
        "id": "c7B300HnCLdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "19c378c1-fafe-4818-edcb-efa22de06032"
      },
      "cell_type": "code",
      "source": [
        "plt.matshow( train_images[0], cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAFSCAYAAABPFzzRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwABhCgAGCFMAMECYAoCB/wEL7nGlb8JprQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 396x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lsFvaPqsFq5u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Verify that the \"true\" label is correct"
      ]
    },
    {
      "metadata": {
        "id": "6nIxGD7cCLdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1478708f-7fd6-404a-9193-2544442d8eb3"
      },
      "cell_type": "code",
      "source": [
        "print(train_labels[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MtSwoHaQCLdb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 6: Reformat the datasets so that we can feed the data to the model we will build  \n",
        "** A 2D CNN model will accept a 4D input data - \\[number of data, height, width, depth of image]**  \n",
        "** So, we will reshape each image of dimension \\[28, 28] to \\[28, 28, 1]**   \n",
        "** Also, the image intensities can be anywhere from 0 to 255 - we want these numbers to be between 0 and 1 **"
      ]
    },
    {
      "metadata": {
        "id": "13ZyN_wxCLdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape( ( 60000, 28, 28, 1 ) )\n",
        "train_images = train_images.astype( 'float32' ) / 255\n",
        "validation_images = validation_images.reshape( ( 10000, 28, 28, 1 ) )\n",
        "validation_images = validation_images.astype( 'float32' ) / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32qh5r4HGoT9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 7: Our network will have 10 output nodes, we need to convert our labels accordingly\n",
        "** Don't you rerun this more than once**   \n",
        "** Verify that the shape of train_labels is (60000, 10) **  "
      ]
    },
    {
      "metadata": {
        "id": "bvDeN5B1G3WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "354eff29-546c-475c-dcc2-5aabb5821cff"
      },
      "cell_type": "code",
      "source": [
        "print(\"Before:\")\n",
        "print( train_labels.shape )\n",
        "print( train_labels[0] )\n",
        "train_labels = to_categorical( train_labels )\n",
        "validation_labels = to_categorical( validation_labels )\n",
        "print(\"After:\")\n",
        "print( train_labels.shape )\n",
        "print( train_labels[0] )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before:\n",
            "(60000,)\n",
            "5\n",
            "After:\n",
            "(60000, 10)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OHUZowOTCLdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 8: Create a neural network with following architecture:  \n",
        "**- The first layer has 16 filters (kernels), each of size 3x3**  \n",
        "**- The third layer has 4 filters (kernels), each of size 3x3**  \n",
        "**- The last layer is a set of 10 neurons - one for each of the 10 digit labels**  \n",
        "\n",
        "#### Notes:\n",
        "**- You could use just the Dense layers to achieve digit identification - CNNs usually deliver better accuracy**  \n",
        "**- Conv2D is the convolutional layer - Conv2D( filters, (filter_height, filter_width), (activation), (input_shape) )**  \n",
        "**- The filter will move through the image pixel by pixel (or \"convolves\") around the image picking up values - output of: 26 x 26**  \n",
        "**- The last layer - 10 neurons for digits between 0 and 9 - Each neuron will contain values be between 0 - 1 and all of the values will sum to 1**  \n",
        "**- We have a probability for a digit prediction - the highest probability will be the model's prediction for the digit**  "
      ]
    },
    {
      "metadata": {
        "id": "ixyuwzFYCLdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "d0639309-90c9-467e-8526-9cc068833dbe"
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add( layers.Conv2D( 16, ( 3, 3 ), activation = 'sigmoid', input_shape = train_images[0, :, :, :].shape ) )\n",
        "model.add( layers.Conv2D( 4, ( 3, 3 ), activation = 'sigmoid' ) )\n",
        "model.add( layers.Flatten() )\n",
        "model.add( layers.Dense( 10, activation = 'softmax' ) )\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 4)         580       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                23050     \n",
            "=================================================================\n",
            "Total params: 23,790\n",
            "Trainable params: 23,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mj9I8_OzCLdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 9: Compile the model and Do the training"
      ]
    },
    {
      "metadata": {
        "id": "F3sh0E3OCLdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "045aeeb2-7283-4205-d1dc-594d794449f9"
      },
      "cell_type": "code",
      "source": [
        "model.compile( optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = [ 'accuracy' ] )\n",
        "model.fit( train_images, train_labels, epochs = 1, batch_size = 256 )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 41s 686us/step - loss: 1.6491 - acc: 0.4396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f642282c4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Cng1uxfwMIco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 10: Evaluate the model on the test validation set"
      ]
    },
    {
      "metadata": {
        "id": "jPqgW345CLdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1d0a7657-cbdb-49ce-d963-e2d824bf9802"
      },
      "cell_type": "code",
      "source": [
        "validation_loss, validation_acc = model.evaluate( validation_images, validation_labels )\n",
        "print( 'validation_acc:', validation_acc )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 307us/step\n",
            "validation_acc: 0.7906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3bwpB6B_CLdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 11: Look into what the model actually predicted\n",
        "** An example of what the model has predicted and comparison with the true classes**\n"
      ]
    },
    {
      "metadata": {
        "id": "yUiGV9R4CLdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "fcb051b0-84a3-4f9a-8e31-598ce494fd51"
      },
      "cell_type": "code",
      "source": [
        "plt.matshow( validation_images[0, :, :, 0], cmap = 'gray' )\n",
        "plt.show()\n",
        "print( validation_labels[0] )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAFSCAYAAABPFzzRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsmeG8ay0BwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 396x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fwrAOqP9CLdz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Visualizing the predictions predictions on the unseen data - this is going to show us how the model is predicting the images**  \n",
        "**  The output is an array of values where each value is associated to a digit**"
      ]
    },
    {
      "metadata": {
        "id": "88ZhvGptCLd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4d559983-bcd4-44b4-a48b-e98131a96f65"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.7f}\".format(x)})\n",
        "\n",
        "predictions = model.predict( validation_images )\n",
        "print( predictions[0] )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0000092 0.0000096 0.0000216 0.0002000 0.0003006 0.0003302 0.0000044\n",
            " 0.9986088 0.0000202 0.0004954]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EO3b5Kn5CLd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** After rounding we can see the output of the prediction**  "
      ]
    },
    {
      "metadata": {
        "id": "lyTTJas1CLd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5af0e9c-c58c-497b-b799-d843f4be79fc"
      },
      "cell_type": "code",
      "source": [
        "print( predictions[0].round() )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_PbETHIHCLd8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 12: How can the model's performance be improved?\n",
        "- Use GPU for training\n",
        "- Increase the number of epochs\n",
        "- Increase the number of filters in the first layer, and subsequent layers\n",
        "- Add more layers into the neural networks \n",
        "- Increase the number of Conv2D layers (i.e. add extra layers)\n",
        "- What is the baseline accuracy (i.e. accuracy of a random model)?"
      ]
    },
    {
      "metadata": {
        "id": "Aiew4WBlCLd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}