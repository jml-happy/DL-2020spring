{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Effect_of_depth_on_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAcnDUEFtlj1",
        "colab_type": "text"
      },
      "source": [
        "# Effect of network depth on learning/prediction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_RwAhqCbbO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYULkdoic8KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "( train_images, train_labels ), ( test_images, test_labels ) = mnist.load_data()\n",
        "print('Validation dataset:')\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMQo41CSc-Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.matshow( test_images[2], cmap = 'gray')\n",
        "plt.show()\n",
        "print(test_labels[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gzk_FmPdAZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the Test Set to do the training (because it is smaller)\n",
        "train_images = test_images.reshape( ( 10000, 28, 28, 1 ) )\n",
        "train_images = train_images.astype( 'float32' ) / 255\n",
        "print(\"Before:\")\n",
        "print( test_labels.shape )\n",
        "print( test_labels[0] )\n",
        "\n",
        "train_labels = to_categorical( test_labels )\n",
        "print(\"After:\")\n",
        "print( train_labels.shape )\n",
        "print( train_labels[0] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpNgVtPEgkoL",
        "colab_type": "text"
      },
      "source": [
        "### I. A model with 4 CNN layers does reasonably well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLG0G3PsdDkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AbdIEs2dJqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit( train_images, train_labels, epochs = 8, batch_size = 10, validation_split = 0.2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggGtujC9gou0",
        "colab_type": "text"
      },
      "source": [
        "## II. A model with too many CNN layers cannot learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTB_P4mGfGIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\n",
        "\n",
        "for i in range(1000):\n",
        "    model.add(Conv2D(filters = 4, kernel_size = 5, activation = 'relu', padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA1CbigdfT8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit( train_images, train_labels, epochs = 8, batch_size = 10, validation_split = 0.2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efbg28xxgrRS",
        "colab_type": "text"
      },
      "source": [
        "## III. A model with (just) many CNN layers also may not learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or0JF-jxf7Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\n",
        "\n",
        "for i in range(16):\n",
        "    model.add(Conv2D(filters = 4, kernel_size = 5, activation = 'relu', padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZGVoT_DgDPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit( train_images, train_labels, epochs = 8, batch_size = 10, validation_split = 0.2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyFa834Fgz-R",
        "colab_type": "text"
      },
      "source": [
        "## IV. BatchNormalization comes to rescue a model with reasonable # of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rbQeixbwL7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\n",
        "\n",
        "for i in range(16):\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters = 4, kernel_size = 5, activation = 'relu', padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 5, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 16, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHAbcIHBwQrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit( train_images, train_labels, epochs = 8, batch_size = 10, validation_split = 0.2 )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}